{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PPGI_UFRJ](imagens/ppgi-ufrj.png)\n",
    "# Fundamentos de Ciência de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "[![DOI](https://zenodo.org/badge/335308405.svg)](https://zenodo.org/badge/latestdoi/335308405)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PPGI/UFRJ 2020.3, 2022.2, 2024.2\n",
    "## Prof Sergio Serra e Jorge Zavaleta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Módulo 2 - Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  **Pandas é a biblioteca de análise de dados em Python**\n",
    "\n",
    ">É uma biblioteca **open source** para análise de dados em Python, de alto desempenho e de fácil uso. Pandas é uma estruturas de dados com eixos rotulados que suportam alinhamento automático ou explícito de dados, evitando erros comuns resultantes de dados desalinhados e do trabalho com dados indexados de forma diferente provenientes de diferentes fontes.\n",
    ">- Possue funcionalidades integradas para lidar com séries temporais.\n",
    ">- Usa as mesmas estruturas de dados para lidar com dados de séries temporais e não temporais.\n",
    ">- Possue operações aritméticas e reduções (como a soma em um eixo) que passariam nos metadados (rótulos dos eixos).\n",
    ">- Tratamento flexível de dados perdidos.\n",
    ">- Merge e outras operações relacionais encontradas em bancos de dados populares (baseados em SQL).\n",
    "\n",
    ">O **kernel** pandas está baseado em duas estruturas de dados primárias nas quais todas as transações, que geralmente são feitas durante a análise de dados são centralizadas em estruturas de **series** e **DataFrames** muito utilizadas em Data Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impotando a biblioteca pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca\n",
    "import pandas as pd # pandas\n",
    "import numpy as np  # numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "> Uma **série** é um objeto semelhante a uma matriz unidimensional que contém uma matriz de dados de qualquer tipo de dados (NumPy) e uma matriz associada aos rótulos ou indices do dados.\n",
    "<img src=\"imagens/series.png\" alt=\"series\" width=\"170\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um objeto serie\n",
    "s0 = pd.Series([4, 7, -5, 3], dtype=np.float64)\n",
    "s0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar indices da serie: index\n",
    "print(s0.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza os valores: values\n",
    "print(s0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma serie com indices de letras\n",
    "indices =['a','b','c','d']\n",
    "valores = [1,-5, 20, -90]\n",
    "#\n",
    "s1 = pd.Series(valores,indices, dtype=np.float32)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma serie com indices numericos\n",
    "indices =['1','2','3','4']\n",
    "valores = [1,-5, 20.0, -90]\n",
    "#\n",
    "s1 = pd.Series(valores,indices)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma serie alaetoria\n",
    "serie = pd.Series([np.random.randn(50)])\n",
    "# visualizar a serie\n",
    "print('Serie:',serie,'Tipo:',type(serie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma serie de uma lista\n",
    "peso_kg = np.linspace(55,80,100)\n",
    "print(peso_kg)\n",
    "len(peso_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir dados numpy em Serie (pandas)\n",
    "pesos = pd.Series(peso_kg)\n",
    "pesos.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrando valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatiar uma serie condicao booleana\n",
    "p60 =pesos[(pesos>60) & (pesos <70)]\n",
    "print(p60)\n",
    "len(p60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatiar uma serie\n",
    "p10_50= pesos[10:50]\n",
    "p10_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificar valores nulos \"false\". Visualiza os 5 valores iniciais (head())\n",
    "n0 = p10_50.isnull()\n",
    "n0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores não nulos \"true\"\n",
    "n1 = p10_50.notnull()\n",
    "n1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecionando valores internos\n",
    "> Se pode selecionar elementos individuais da mesma forma como é feita nas matrizes numpy, especificando a **chave** (index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando o indice na serie n1\n",
    "v0 = p10_50[np.random.randint(10,50,1)]\n",
    "v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando o indice na serie n1 = p10_50[x,y]: x, y:indices\n",
    "i1 = np.random.randint(10,20,1)\n",
    "i2 = np.random.randint(21,50,1)\n",
    "#print(type(i1))\n",
    "#v1 = pesos[[i1,i2]]\n",
    "v1 = pesos[[int(i1),int(i2)]]               \n",
    "v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribuição de valores aos elementos\n",
    "> A atribuição de novos valores aos elementos da série pode ser feito selecionando o **índice** ou rótulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## atribuir valor -1 al elemento de indice 60\n",
    "pesos[60] = -1\n",
    "pesos[[59,60,61]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir séries a partir de  matrizes NumPy ou de outras séries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matriz numpy -> valores passados por referencia\n",
    "m0 = np.array([1,1,2,3,4,5,-1, -1])\n",
    "S0 = pd.Series(m0)\n",
    "S0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os valores da serie são passados por referencia\n",
    "S0[7] = 10\n",
    "print(S0)\n",
    "print(m0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações e funções matemáticas\n",
    "> Nas séries podem ser usadas todas as operações matemáticas aplicadas nos \"arrays\" numpy **(+,-,*,/)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando a serie S0\n",
    "ds = S0*4 #S0 + 4 # S0 - 2 # S0/4\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando funções matematicas\n",
    "l0 = np.log(S0)\n",
    "l0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando valores\n",
    "> A função **unique()** retorna uma matriz com valores únicos, excluindo duplicatas, embora não necessariamente em ordem.\n",
    "\n",
    "> **value_counts()** retorna os valores únicos e conta as ocorrências na série.\n",
    "\n",
    "> **isin()** avalia a pertinência dos elementos na série. Esta função informa se os valores estão contidos na estrutura de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usando unique() em l0\n",
    "u0 = l0.unique()\n",
    "print(u0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retorna os valores unicos e o numero de ocorrencias deles\n",
    "u1 = l0.value_counts()\n",
    "u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existem valores 0 na serie?\n",
    "u2 = l0.isin([0])\n",
    "u2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 e 3 estão na serie?\n",
    "u3 = l0.isin([0,3])\n",
    "u3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtra valores usando isin()\n",
    "u4 = l0[l0.isin([0,3])]\n",
    "u4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operações entre séries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando serie 1\n",
    "mydict1 = {'red': 2000, 'blue': 1000, 'yellow': 500,'orange': 1000}\n",
    "serie1 = pd.Series(mydict1)\n",
    "print(serie1)\n",
    "print()\n",
    "# serie 2\n",
    "mydict2 = {'red':400,'yellow':1000,'black':700}\n",
    "serie2 = pd.Series(mydict2)\n",
    "print(serie2)\n",
    "print()\n",
    "ss = serie1 + serie2\n",
    "print(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "> Um **DataFrame** representa uma estrutura de dados tabular semelhante a uma planilha contendo uma coleção ordenada de colunas, cada uma das quais pode ter um tipo de valor diferente (numérico, string, booleano etc.). O **DataFrame** tem um índice para linha e coluna.\n",
    "<img src=\"imagens/dataframes.png\" alt=\"dataframes\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um dataframe: indices = {Idade, Altura,Peso}\n",
    "df = pd.DataFrame({'Idade':np.random.randint(25,high=50,size=40),\n",
    "                  'Altura':1.20+np.random.rand(40),\n",
    "                  'Peso':np.linspace(55,90,40)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar os 5 primeiros registros do dataframe\n",
    "df.head(20) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algumas metricas sobre os dados\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Percentil - divisão da amostra em percetuais.\n",
    ">> - 25% dos elementos são inferiores a X.Y anos, X.Y m e X.Y kg.\n",
    ">> - Metade dos elementos são inferiores a X.Y anos, X.Y m e X.Y kg.\n",
    ">> - 75% dos elementos são inferiores a X.Y anos, X.Y m e X.Y kg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar os nomes das colunas\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar os valores das colunas\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar o DataFrame como Matriz(transposta)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"fatiar\" um dataframe\n",
    "idade = df['Idade']\n",
    "idade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peso =df['Peso']\n",
    "peso.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatiar selecionando linhas\n",
    "df1 = df[(df.Idade > 30) & (df.Idade < 40)]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operacoes com colulas Peso/Altura\n",
    "df['peso-altura']= np.round(df['Peso']/df['Altura'],decimals=2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de arquivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Existem funções que permitem ler dados de diversos formatos. Um dos mais usados em **datasets** é o **CSV** - *Comma Separated Value* (Valores Separados por Vírgulas), que podem ser importados e exportados pela maioria de aplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data          | Formato       | Reader        | Writer        |\n",
    "| :---:         | :---:         | :---:         | :---:         |\n",
    "| CSV           | Texto         | read_csv      | to_csv        |\n",
    "| JSON          | Texto         | read_json     | to_json       |\n",
    "| HTML          | Texto         | read_html     | to_html       |\n",
    "| MS_EXCEL      | Binário       | read_excel    | to_excel      |\n",
    "| SQL           | SQL           | read_sql      | to_sql        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Colab (usar dados do PC)\n",
    "\n",
    "> ```from google.colab import drive```\n",
    "\n",
    "> ```drive.mount('/content/drive')```\n",
    "\n",
    "> Seguir o link para copiar o código e colar o espaço solicitado. **My Drive** é o google drive, logo adicionar o caminho do diretório para fazer a leitura do arquivo desejado.\n",
    "\n",
    "> ```dadosx = pd.read_csv('/content/drive/My Drive/datasets/covid19_confirmed.csv',delimiter=',')```\n",
    "\n",
    "> ```dadosx.head(10)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Importar dados do GitHub\n",
    "> ```!git clone https://github.com/zavaleta/Fundamentos_DS```\n",
    "> ### Leitura dos dados\n",
    "> ```file_data = pd.read_csv('Fundamentos_DS/data/file.csv')```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo 1: Covid19 - Pernambuco\n",
    "prouni = pd.read_csv('data/cursos-prouni2020.csv',delimiter=',',decimal=',')\n",
    "prouni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando as colunas\n",
    "prouni.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando valores do dataframe\n",
    "valores = prouni.values\n",
    "valores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecioando elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando coluna\n",
    "turno = prouni[['turno','mensalidade']]\n",
    "turno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando coluna\n",
    "campus = prouni['campus_nome']\n",
    "campus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza elementos usando o indice da fila\n",
    "loc_campus = campus.loc[2]\n",
    "loc_campus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza elementos usando o 2 indices das filas\n",
    "loc_campus1 = campus.loc[[2,10]]\n",
    "loc_campus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza elementos usando o indices da fila\n",
    "loc_campus2 = campus[2:10]\n",
    "loc_campus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_campus3 = campus.iloc[2:10]\n",
    "loc_campus3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminar uma coluna\n",
    "#del dataFrme['nome_coluna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turno tem alguma valor nulo?\n",
    "tn = turno.isnull()\n",
    "tn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivos JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_json = pd.read_json('data/article-prov.json')\n",
    "print(read_json)\n",
    "#write_json = pd.to_json('data/file.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquivos MS_EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando um arquivo MS_EXCEL\n",
    "file_excel = prouni.loc[:5,:'mensalidade']\n",
    "print(file_excel)\n",
    "# gravando um arquivo excel\n",
    "file_excel.to_excel('data/excel_teste.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_excel = pd.read_excel('data/excel_teste.xlsx',index_col=0)\n",
    "read_excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *iloc*\n",
    "> As linhas de um DataFrame podem ser acessadas por meio do método **iloc**, que usa uma sintaxe semelhante à de uma lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza os dados\n",
    "prouni.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza a linha = 1\n",
    "prouni.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza as linhas 1 ao 4\n",
    "prouni.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatiar um data frame\n",
    "prouni.iloc[:3,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acessando as filas pares (indices)\n",
    "pares = prouni.iloc[prouni.index % 2 == 0]\n",
    "pares.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *loc*\n",
    "> **loc** é semelhante ao **iloc**, mas permite indexar um DataFrame por meio de nomes de coluna ou rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza a coluna 1\n",
    "prouni.loc[0,:'grau']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fatiar um dataFrame\n",
    "p0 = prouni.loc[:'grau',:'curso_id']\n",
    "p0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reindexar\n",
    "> O método de reindexação em **Pandas**, significa criar um novo objeto com os dados em concordância com um novo índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas original\n",
    "rein0 = pd.Series([4.5, 7.2, -5.3, 3.6], index=['a', 'b', 'c', 'd'])\n",
    "rein0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mudando index\n",
    "rein1 = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\n",
    "rein1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reindexando\n",
    "r = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 6])\n",
    "rein2 = r.reindex(range(6),method='ffill')\n",
    "rein2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando entradas de uma fila (axis=0) ou coluna (axis=1) - DROP\n",
    "> Eliminar uma ou mais entradas de uma fila/coluna de uma matriz de índice ou de uma lista sem entradas. o método **drop** retornará um novo objeto com o valor indicado ou valores deletados de uma fila/coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando a serie\n",
    "d0 = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop -> elimiando a fila 'c'\n",
    "dc = d0.drop('c')\n",
    "dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop -> elimiando a fila 'c'\n",
    "d_ae = d0.drop(['a','e'])\n",
    "d_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4x4 = pd.DataFrame(np.arange(16).reshape((4, 4)),index=['RJ', 'SP', 'AC', 'CE'],\n",
    "                 columns=['um', 'dois', 'três', 'quatro'])\n",
    "m4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop filas (index)\n",
    "dfil = m4x4.drop(['RJ','CE'])\n",
    "dfil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop coluna (axis=1)\n",
    "dcol = m4x4.drop('três',axis=1)\n",
    "dcol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop coluna (axis=1)\n",
    "dcol0 = m4x4.drop('um',axis=1)\n",
    "dcol0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop fila (axis=1)\n",
    "dfil0 = m4x4.drop('SP',axis=0)\n",
    "dfil0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecionar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtrar por colunas\n",
    "m1 = m4x4[['um','dois']]\n",
    "m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtra elementos > 4\n",
    "m2 = m4x4[m4x4 > 4]\n",
    "m2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fatiamento (slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice index\n",
    "m3 = m4x4['AC':'CE']\n",
    "m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice index\n",
    "m4x4['AC':'CE']=5\n",
    "m4x4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamentos de falta de dados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Com frequência é encontrado datasets com falta de dados, com dados nulos ou com dados incoerentes. Estes datasets devem ser limpados e homogeneizados antes de realizar qualquer operação.\n",
    "\n",
    ">Pandas têm duas formas de tratar dados com valores **null**, **NaN** ou **NA**: Usando uma **máscara** que indica perda de valores ou escolher um valor **sentinela** que indica entrada ausente.\n",
    "\n",
    ">1. **Máscara**: A máscara pode ser uma matriz booleana totalmente separada ou pode envolver a representação de um bit para indicar localmente o status nulo de um valor.\n",
    "\n",
    ">2. **Sentinela**: o valor do sentinela pode ser uma convenção específica de dados, como por exemplo, para indicar um valor inteiro com **-999** ou otro valor determinado por convenção. O valor **NaN** é uma convenção da IEEE para determinar um valor de ponto flutuante ausente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### None\n",
    ">É o primeiro valor sentinela usado por Pandas, tratado como um objeto do Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando as bibliotecas \n",
    "import numpy as np               # numpy\n",
    "import pandas as pd              # pandas\n",
    "import matplotlib.pyplot as plt  # graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo\n",
    "notas_none = np.array([4.0, 7.0, 6.5, None, 10.0, 8.8, None, 9.0, 4.0, 7.0, 9.5])\n",
    "print('A:',notas_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operção não definida!!!\n",
    "#notas_none.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN\n",
    ">Dados numéricos ausentes. (*Not a Number*). Valor de ponto flutuante especial reconhezidos pelos sistemas que usam a representação padrão de ponto flutuante da IEEE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notas_nan = np.array([4.0,7.0, 6.5, np.nan, 10, 8.8, np.nan, 9.0])\n",
    "print('Notas:',notas_nan)\n",
    "print('Tipo:',notas_nan.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operacoes aritmeticas: soma\n",
    "v = 1 + np.nan\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operacoes aritmeticas: multiplicacao\n",
    "v1 = 0*np.nan\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agregados\n",
    "notas_nan.sum(), notas_nan.min(), notas_nan.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN e None em Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serie de pandas\n",
    "serie = pd.Series([2,3.0, np.nan, 8, 5.0, None,-1.0])\n",
    "serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serie de pandas\n",
    "x_int = pd.Series(range(6), dtype=int)\n",
    "x_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_int[0] = None\n",
    "x_int[3]  = None\n",
    "x_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operações com valores nulos\n",
    "> - **isnull()**: Gera uma mácara booleana indicandoi valores ausentes.\n",
    "> - **notnull()**: Retorna os valores não nulos\n",
    "> - **dropna()**: Retorna a serie ou dataframe sem valores nulos.\n",
    "> - **fullna()**: Retorna uma copia dos dados com valores ausentes preenchidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplos detectando valores nulos\n",
    "serie_nulos = pd.Series([-1.0, 1, 4.5, np.nan, 'oi',None, 10])\n",
    "print('Serie:',serie_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores não nulos\n",
    "serie_nulos[serie_nulos.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando valores nulos\n",
    "n_nulos = serie_nulos.dropna()\n",
    "n_nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "df = pd.DataFrame([[1, np.nan, 2,5],[2, 3, 5, -1.0],[np.nan, 4, 6, 20]])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna em dataframe\n",
    "df1 = df.dropna()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina colunas\n",
    "df2 = df.dropna(axis='columns')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina filas ou linhas\n",
    "df3 = df2 = df.dropna(axis='rows')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimina todas as colunas com valores nulos\n",
    "print(df)\n",
    "df3 = df.dropna(axis=1)\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenchendo valores nulos\n",
    "dados = pd.Series([1, np.nan, 2, None, 3.0, 6.0, 7], index=list('abcdedg'))\n",
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preenchendo com zero\n",
    "d = dados.fillna(0)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos aritméticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criar 2 dataframes\n",
    "M1 = pd.DataFrame(np.arange(8.).reshape((2, 4)), columns=list('abcd'))\n",
    "print(M1)\n",
    "M2 = pd.DataFrame(np.arange(15.).reshape((3, 5)), columns=list('abcde'))\n",
    "print(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método add\n",
    "M3 = M1 + M2\n",
    "M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método add - sub - div - mul\n",
    "M4 = M1.div(M2,fill_value=0)\n",
    "M4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas descritivas\n",
    "> Os objetos pandas são munidos de um conjunto de métodos matemáticos e estatísticas comuns, estes métodos extraem um único valor de uma série ou de uma série de valores das linhas ou colunas de um DataFrame.\n",
    "\n",
    "> Os métodos estatísticos auxiliam na compreensão e análise do comportamento dos dados.\n",
    "> **sum**, **mean**,**median**,**varience**,**covariance**,**correlation**, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados\n",
    "df_data =  pd.DataFrame(np.random.randn(10, 5), index = pd.date_range('1/1/2020', periods=10),\n",
    "                       columns = ['A', 'B', 'C', 'D','E'])\n",
    "print(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soma de  todas as colunas\n",
    "sc = df_data.sum() # sum(axis=0) # soma cada coluna\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soma cada fila (row)\n",
    "sc_1 = df_data.sum(axis=1)\n",
    "print(sc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media das colunas\n",
    "media_c = df_data.mean()\n",
    "print(media_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media das filas\n",
    "media_f = df_data.mean(axis=1)\n",
    "print(media_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caluclos usando windows = n: (n+(n-1)+(n-2)=/n) --> n=3 e mean()\n",
    "print(df_data.rolling(window=3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodos de agregação - rolling\n",
    "print(df_data)\n",
    "rol = df_data.rolling(window=3,min_periods=1)\n",
    "print(rol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate todas as collunas\n",
    "print(rol.aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coluna A\n",
    "print(rol['A'].aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  aggregate multiples colunas\n",
    "print(rol[['A','B']].aggregate(np.sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate multiples funções a uma coluna\n",
    "df_group = rol['C'].aggregate([np.sum,np.mean,np.median,np.std])\n",
    "print(df_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into groups - agrupar\n",
    "club_data = {'Club': ['Flamengo', 'Inter', 'SP', 'Fluminense', 'Gremio',\n",
    "   'Flamengo', 'Flamengo', 'Inter', 'Gremio', 'Santos', 'Santos', 'Corinthians'],\n",
    "   'Rank': [1, 2, 2, 3, 3,4 ,1 ,1,2 , 4,1,2],\n",
    "   'Ano': [2014,2015,2014,2015,2014,2015,2016,2017,2016,2014,2015,2017],\n",
    "   'Pontos':[876,789,863,673,741,812,756,788,694,701,804,690]}\n",
    "df_club = pd.DataFrame(club_data)\n",
    "print(df_club)\n",
    "print()\n",
    "group_ano = df_club.groupby('Ano')    # agrupado por ano\n",
    "print('Ano:',group_ano.groups)\n",
    "print()\n",
    "ag_pontos_anos = group_ano['Pontos'].agg([np.sum, np.mean,np.var,np.std]) # ano e pontos\n",
    "print(ag_pontos_anos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulando bancos de dados\n",
    "> Em muitas aplicações, os dados estão armazenados em formatos ineficientes para guardar grandes volumes de dados. Os bancos de dados relacionais baseados em SQL (como SQL Server, PostgreSQL e MySQL) são amplamente usados nesses casos, e muitos bancos de dados alternativos non-SQL (chamados de NoSQL) se tornaram bastante populares. A escolha do banco de dados geralmente depende das necessidades de desempenho, integridade de dados e escalabilidade de uma aplicação.\n",
    "\n",
    "> O pandas tem algumas funções para simplificar o processo de carregar dados de SQL em um DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will use an in-memory SQLite database using Python’s built-in sqlite3 driver\n",
    "import sqlite3\n",
    "# criar a tabela fcd\n",
    "query = \"\"\"\n",
    "CREATE TABLE fcd\n",
    "(a VARCHAR(20), b VARCHAR(20), c REAL, d INTEGER);\"\"\"\n",
    "# conexao com o sqlite3\n",
    "con = sqlite3.connect(':memory:')\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserir dados\n",
    "data = [('Araruama', 'Cabo frio', 12.5, 20),\n",
    "        ('Niterói', 'Nova Iguaçu', 3.6, 15),\n",
    "        ('Petropolis', 'Teresopolis', 2.0, 10)]\n",
    "# \n",
    "stmt = \"INSERT INTO fcd VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retorna as tuplas\n",
    "cid_0 = con.execute('select * from fcd') # cursor\n",
    "filas = cid_0.fetchall()\n",
    "filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description\n",
    "des = cid_0.description\n",
    "des"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(filas, columns=list(zip(*cid_0.description))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# leitura do sql em pandas = dataframe\n",
    "import pandas.io.sql as sql\n",
    "sql0 = sql.read_sql('select * from fcd', con)\n",
    "print(sql0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização em Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gerando os valores\n",
    "df_grafico = pd.DataFrame(np.random.randn(10,5),index=pd.date_range('1/1/2020',\n",
    "   periods=10), columns=list('ABCDE'))\n",
    "df_grafico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualização do dataframe completo\n",
    "df_grafico.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot\n",
    "df_grafico.plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacket = True\n",
    "df_grafico.plot.bar(stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# horizontal\n",
    "df_grafico.plot.barh(stacked=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogramas\n",
    "df_grafico.plot.hist(bins=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots\n",
    "df_grafico.plot.box();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area plots (valores positivos)\n",
    "df_area = pd.DataFrame(np.random.rand(10, 5), columns=['a', 'b', 'c', 'd','e'])\n",
    "df_area.plot.area();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "df_area.plot.scatter(x='a',y='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "df_area.plot.pie(y='a',subplots=True,figsize=(5,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots\n",
    "df_area.plot.pie(subplots=True,figsize=(15,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grandes volumes de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exemplo 2: dataset - covid19-deaths\n",
    "#ctotal = pd.read_csv('data/covid-19_casos_full.csv',delimiter=',')\n",
    "ctotal = pd.read_csv('data/rio_full_casos.csv',delimiter=',')\n",
    "ctotal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza o total de registros\n",
    "print('Total de Registros :> ',len(ctotal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estado_rj = ctotal[ctotal['state']=='RJ']\n",
    "estado_rj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split para rio de janeiro\n",
    "#casos_rj = pd.DataFrame(estado_rj[estado_rj['city'] == 'Rio de Janeiro'])\n",
    "#casos_rj.to_csv('data/rio_full_casos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidade_rj = estado_rj[estado_rj['city'] == 'Rio de Janeiro']\n",
    "cidade_rj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores para o grafico\n",
    "y = cidade_rj['new_deaths']\n",
    "y1 = cidade_rj['new_confirmed']\n",
    "#print(len(y))\n",
    "x = np.arange(0,350)\n",
    "#print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "fig, cov = plt.subplots(nrows=1, figsize=(10, 5))\n",
    "cov.plot(x,y,'r',linewidth=1.5, label='Mortos')\n",
    "cov.plot(x,y1,'b',linewidth=1.5, label='Casos confirmados')\n",
    "cov.legend()\n",
    "cov.grid()\n",
    "plt.title('Covid-19 - 18/02/2021')\n",
    "plt.xlabel('Rio de Janeiro')\n",
    "plt.ylabel('Total');\n",
    "# gravando a figura\n",
    "#fig.savefig('images/conf-mor.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercicios**:\n",
    "1. Mostre os valores e colunas dos datasets (data, populaçao estimada, confirmados e mortos)\n",
    "2. Construa mini datasets usando os estados como fator de corte.\n",
    "3. Apresente os gráficos dos mini datasets (use as colunas adequadas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "####  Fudamentos para Ciêcia de Dados &copy; Copyright 2021, 2022, 2024 - Sergio Serra & Jorge Zavaleta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
